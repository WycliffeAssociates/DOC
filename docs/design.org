#+AUTHOR:
* Design notes
** Requirements
*** Requirement
Allow creating a document out of any combination of resources from any
combination of languages supported (in translations.json).
*** Requirement
Produce PDF document.
*** Requirement
If generation of PDF document takes longer than X threshold of time,
then return a message to the user giving link where document will
eventually be found. E.g., display message to user in interface, say
after a cache miss on document request, or, via email. Details to be
determined.
*** Requirement
Handle TN, TA, TW, TQ, ULB, UDB resource requests. Later perhaps also
OBS, etc..
** How to run a demo for yourself
*** Get the code
Get the DOC repo:

#+begin_src shell
git clone https://github.com/linearcombination/DOC.git
#+end_src

*** Run test suite inside the Docker container:
**** One command to take down old running containers, build the new, and run all tests
#+begin_src shell
make all
#+end_src

Note: this will take about a half hour to an hour give or take depending on your
network latency.

The generated PDFs are copied from the Docker container to the
=docker_document_output= directory at the base of the repo for ease of perusal.

**** Or, instead of =make all= you can do one thing at a time using multiple Makefile targets
***** Build the container

First take down any running containers from previous runs:

#+begin_src shell
make down
#+end_src

then ...
#+begin_src shell
make build
#+end_src
***** Or, build the container the 2+Nth time from scratch

First take down any running containers from previous runs:

#+begin_src shell
make down
#+end_src

Note: Sometimes, like if a docker process was interrupted by keyboard
interrupt, you may have to be a bit more forceful with Docker and use
'=docker stop id_of_image_obtained_by_docker_ps_-a'= and then '=docker rm
id_of_image_obtained_by_docker_ps-a'= to clear out the old Docker
images from a previous run.

then

#+begin_src shell
make build-no-cache
#+end_src

if you really want to make sure you are getting a clean, from scratch,
build with no caching.

***** Run the tests
#+begin_src shell
make test
#+end_src

or, alternatively, run the unit tests separate from the end-to-end
tests:
#+begin_src shell
make unit-tests
#+end_src

and
#+begin_src shell
make e2e-tests
#+end_src
*** Run demo outside Docker container
**** Create and activate the virtual environment

#+begin_src shell
python3 -m venv .venv
source .venv/bin/activate
# or source .venv/bin/activate.fish
#+end_src

then ...

**** Install dependencies
#+begin_src shell
make local-install-deps-dev
#+end_src

this will setup your environment tools and install production and
development dependencies for our app.

Then ...

**** Install our app in editable mode

#+begin_src shell
pip install -e .
#+end_src

then ...

**** Run Redis Docker instance

 #+begin_src shell
 docker run -p 6379:6379 redis
 #+end_src

**** Run celery

In another terminal window, in project root directory, in virtual env (source .venv/bin/activate[.fish]):
 #+begin_src shell
 celery --app=document.domain.worker.app worker  --loglevel=DEBUG -E
 #+end_src

**** (optional) Run flower (a celery dashboard)

In another terminal window, in project root directory, in virtual env:
 #+begin_src shell
 celery --broker=redis:// --result-backend=redis:// flower
 #+end_src

**** Run API

In another terminal window, in project root directory, in virtual env:
 #+begin_src shell
 make local-server
 #+end_src

**** Build and run the frontend

In another terminal window, in cd <project-root-directory>/frontend:
 #+begin_src shell
 npm run allbuildandrun
 #+end_src

**** Deal with our (required) frontend envvars hack:

In another terminal window, in cd <project-root-directory>/frontend:
 #+begin_src shell
 export BACKEND_API_URL=http://localhost:5005
 cp envvars.js dist/assets/ && envsubst < dist/assets/envvars.js | sponge dist/assets/envvars.js
 #+end_src

**** Note: how to handle situation if you run into runtime error with lxml

If you get a runtime error (which you'll see in the terminal window
from step 2 above) when interacting with the app about bs4
module not having the lxml parser installed/available then you may
need to do (in the project root dir with the venv activated):
 #+begin_src shell
 pip uninstall lxml
 pip install cython # Make double sure cython is installed (it should already have been)
 pip install lxml  # You should see pip invoking to build the lxml wheel as a C extension
 #+end_src
Then restart steps 2, 3, and 4 above.



**** Use the UI

Once all 6 steps are running fine you can navigate to
http://localhost:4173 to access the app and interact with it.

**** (optional) Use the celery dashboard

And then, if desired, you can navigate to http://localhost:5555 to
access the flower celery dashboard.

**** Run a quick smoke test (runs one quick test)
#+begin_src shell
make local-smoke-test-with-translation-words
#+end_src

then ...
**** Run unit tests
#+begin_src shell
make local-unit-tests
#+end_src

then ...
**** Run e2e tests
#+begin_src shell
make local-e2e-tests
#+end_src

** Interactions at a high level

#+begin_src plantuml :file wa_design_sequence_diagram1.png :exports results
UI_biel -> app.document_endpoint: JSON document request
app.document_endpoint -> document_generator.main: passing resources from request
#+end_src

#+RESULTS:
[[file:wa_design_sequence_diagram1.png]]


=app.document_endpoint= passes back a JSON dict containing any messaging and
the URL of the generated document for display to the requesting user
(by =BIEL=).

** Auto-generated system diagram
Regenerate image:

#+begin_src shell  :results silent
cd ..
source .venv/bin/activate && make generate-class-diagrams
#+end_src

[[file+sys:classes.png]]
** Caching design
The system has two levels of caching:
1. PDF document,
   and a second lower level caching mechanism:
2. resource asset file caching

For (1), if the PDF document has previously been requested and built
and is 'fresh' according to the caching policy expressed in
=file_utils.asset_file_needs_update=, then immediately serve the PDF
document to the requesting user.

For (2), if any of the =DocumentRequest= instance's =ResourceRequest=
instances have been obtained from the cloud before and are 'fresh'
according to the caching policy expressed in
=file_utils.asset_file_needs_update=, then don't fetch said resource
asset files again, instead reuse the asset files already obtained.

Also, in level (2): =translations.json= is obtained
according to the caching policy expressed in
=file_utils.source_file_needs_update=.
** Handling links
Translation notes can have links to translation words.

Translation notes can have links to scripture verses.

Translation words can have links to translation notes.

Translation words can have links to scripture verses.

There may be other such inter-dependencies between resource types.

Problem: A document request may include translation notes, but not
translation words, or vice versa. What should be done in such cases
and others like them?

1. Remove such links including the prose leading up to them and
   following, e.g., (See also: _link_, _link_, _link_ blah blah blah)
   a. Removing just those links could render the prose that includes
   them non-sensical, for instance if later prose refers back to the
   links.
2. Instead of removing just the non-linkable links, remove the whole section
   that includes them.
   a. Loss of commentary - which is undesirable.
3. Leave the links, they'll render visually, but just won't work as
   links unless the resource type they reference is also part of the
   document request. This is the choice I have implemented.

Answer: 3
