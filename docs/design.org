#+AUTHOR:
* Design notes
** Requirements
*** Requirement
Allow creating a document out of any combination of resources from any
supported (in translations.json) language.
*** Requirement
Produce PDF final document.
*** Requirement
If generation of PDF document takes longer than X threshold of time,
then return a message to the user giving link where document will
eventually be found. E.g., display message to user in interface, say
after a cache miss on document request, or, via email. Details to be
determined.
*** Requirement
Handle TN, TA, TW, TQ, ULB, UDB resource requests. Later perhaps also
OBS, etc..
** How to run a demo for yourself
*** Get the code
Get the tools repo:

#+begin_src shell
git clone https://github.com/linearcombination/tools.git
#+end_src

Then cd into the tools directory you just creating by cloning.
*** Run demo inside the Docker container:
**** One command to take down old running containers, build the new, and run all tests
#+begin_src shell
make all
#+end_src

Warning: this will take a _long_ time!

If you don't want to have this running for so long then do this
instead:

#+begin_src shell
make unit-tests
#+end_src

The generated PDFs are copied from the Docker container to the
=docker_pdf_output= directory at the base of the repo.

For ease of stakeholders, one or more example PDFs created by the test
runs are committed to the git repo in the =docker_pdf_output=
directory.
**** Or, you can do one thing at a time using multiple Makefile targets
***** Build the container

First take down any running containers from previous runs:

#+begin_src shell
make down
#+end_src

#+begin_src shell
make build
#+end_src
***** Or, build the container the 2+Nth time from scratch

First take down any running containers from previous runs:

#+begin_src shell
make down
#+end_src

Note: Sometimes you have to be a bit more forceful with Docker and use
=docker stop idofimage= and =docker rm idofimage= to clear out the old
Docker images from a previous run.

then

#+begin_src shell
make build-no-cache
#+end_src


***** Run the tests
#+begin_src shell
make test
#+end_src

*** Run demo outside Docker container
**** Create and activate the virtual environment

#+begin_src shell
python3 -m venv venv
source venv/bin/activate
# or source venv/bin/activate.fish
#+end_src

then ...

**** Install pip-tools
#+begin_src shell
pip install pip-tools
#+end_src

then ...

**** Install dependencies
#+begin_src shell
make local-install-deps-dev
#+end_src

this will install production and development dependencies for our app.

Then ...

**** Install our app in editable mode

#+begin_src shell
pip install -e .
#+end_src

then ...

**** Run a quick smoke test (runs one quick test)
#+begin_src shell
make local-smoke-test
#+end_src

then ...
**** Run unit tests
#+begin_src shell
make local-unit-tests
#+end_src

**** Run e2e tests
#+begin_src shell
make local-e2e-tests
#+end_src

** (Needs updating) Interactions at a high level

#+begin_src plantuml :file wa_design_sequence_diagram1.png :exports results
UI_biel -> app.document_endpoint: JSON document resources request
app.document_endopint -> DocumentGenerator: instantiate DocumentGenerator\npassing resources from request
#+end_src

#+RESULTS:
[[file:wa_design_sequence_diagram1.png]]


=DocumentGenerator= passes back a JSON dict containing any messaging and
the eventual location of the generated document for display to the
requesting user (by =BIEL=), or the document itself (depending on how
long it takes to generate).

#+begin_src plantuml :file wa_design_sequence_diagram2.png :exports results
DocumentGenerator -> DocumentGenerator: generate document request key unique to set of resources requested, e.g., a request for two resources: ml-ulb-gen-en-ulb-wa-gen.
DocumentGenerator -> ResourceFactory: using Factory Method design pattern, for each resource, instantiate Resource subclasses from document request based on resource type
DocumentGenerator <- ResourceFactory: Return either USFMResource, TAResource, TNResource, TQResource, TWResource
Resource ->  Resource: find location
Resource ->  ResourceJsonLookup: lookup: find URL for resource
Resource <-- ResourceJsonLookup: return URL
Resource ->  Resource: get (clone or download) associated files from URL
Resource <-- Resource: remember locations of acquired files
Resource -> Resource: initialize other instance vars of resource based on acquired files
Resource -> Resource: get content, i.e., convert Resource's content to HTML
DocumentGenerator -> DocumentGenerator: for each resource, concatenate each Resources' HTML
DocumentGenerator -> DocumentGenerator: enclose concatenated HTML bodies in an HTML and body element with styling
DocumentGenerator -> DocumentGenerator: convert HTML to PDF using pandoc
#+end_src

#+RESULTS:
[[file:wa_design_sequence_diagram2.png]]


A problem with the old design was that it had one class, =TnConverter=,
doing all the work. This monolithic design resulted in copious
conditional logic in order to deal with handling different types of
resources differently, e.g., USFM files, translation notes, etc..

This new version of the design has extracted logic paths unique to
each resource type and relocated them into Resource subclasses,
created via a factory method (=ResourceFactory=). These subclasses share
a clean interface: =find_location=, =get_files=, =initialize_properties=,
=get_content=. The work of =find_location= is delegated to
=ResourceJsonLookup= for all instances. =get_files= is also common to all
subclasses and not specialized from the =Resource= superclass.
Specialization in each subclass happens in the =initialize_properties=
and =get_content= methods.

This new design has also replaced the design of passing around a
dictionary within =DocumentGenerator=. Each resource that is part of a
single document request is now fully reified into its own object and
=DocumentGenerator= maintains a collection of these Resource instances.

=DocumentGenerator= also now maintains a unique key for each particular
collection of resources in the document generation request. This will
make it possible in a future design to simply lookup, if it exists, an
already finalized and generated document if one with the same
resources and order has been requested in the past. This should
greatly improve UX experience due to cutting out all the document
generation processing time.

#+begin_src plantuml :file wa_design_class_diagram_resources.png :exports results
Resource *-- ResourceJsonLookup
Resource : find_location()
Resource : get_files()
Resource : {abstract} initialize_properties()
Resource : {abstract} get_content()
note top of Resource: Partially abstract superclass that handles behavior common to all resources
Resource <|-- USFMResource
' USFMResource : +find_location()
' USFMResource : +get_files()
USFMResource : +initialize_properties()
USFMResource : +get_content()
Resource <|-- TResource
TResource : +_discover_layout()
TResource : +_convert_md2html()
note top of TResource: superclass that handles behavior common to all non-USFM resources
TResource <|-- TNResource
' TNResource : +find_location()
' TNResource : +get_files()
TNResource : +ihitialize_properties()
TNResource : +get_content()
TResource <|-- TAResource
' TAResource : +find_location()
' TAResource : +get_files()
TAResource : +ihitialize_properties()
TAResource : +get_content()
TResource <|-- TQResource
' TQResource : +find_location()
' TQResource : +get_files()
TQResource : +ihitialize_properties()
TQResource : +get_content()
TResource <|-- TWResource
' TWResource : +find_location()
' TWResource : +get_files()
TWResource : +ihitialize_properties()
TWResource : +get_content()
#+end_src

#+RESULTS:
[[file:wa_design_class_diagram_resources.png]]


The interface for ResourceLookup has not changed since the last
design, but some of the underlying implementation details have that
are not relevant to this design document.

#+begin_src plantuml :file wa_design_class_diagram.png :exports results
ResourceLookup <|-- ResourceJsonLookup
ResourceLookup : {abstract} lookup()
note top of ResourceLookup : Abstract superclass which exists only\nfor documentation and design looking\nforward to ResourceGraphQLLookup.\nIt is definitely not necessary for the system to work
ResourceJsonLookup : +lookup()
ResourceLookup <|-- ResourceGraphQLLookup
note bottom of ResourceGraphQLLookup : Does not currently exist,\n but could replace ResourceJsonLookup one day.\nWith this design, call sites could largely\nremain unchanged.
ResourceGraphQLLookup : +lookup()
#+end_src

#+RESULTS:
[[file:wa_design_class_diagram.png]]


As mentioned above a =DocumentGenerator= accepts a document generation
request composed of resources. =DocumentGenerator= instantiates the
appropriate =Resource= subclass based on the resource type. Each
=Resource= instance composes one =ResourceJsonLookup= to which it delegates
lookup tasks.

#+begin_src plantuml :file wa_design_class_diagram2.png :exports results
DocumentGenerator o-- Resource
Resource *-- ResourceJsonLookup
note top of DocumentGenerator : This used to be called TnConverter.
note bottom of Resource : Already discussed above, e.g., USFMResource, TAResource, TNResource, TQResource, or TWResource
note bottom of ResourceJsonLookup : This is where the translations.json API is queried
#+end_src

#+RESULTS:
[[file:wa_design_class_diagram2.png]]

** Docker container
There isn't much to say about the docker container except that it
provides the runtime environment, obviously. The only significant new
detail is that fastapi can be specified to run on a particular IP and
port (seen in =docker-compose.yaml=) which =BIEL= will know and use when
submitting requests.

In a later iteration toward the end, Fastapi will presumably be load
balanced. Further, to protect its pool of workers from being tied up
by long running client requests from =BIEL=, one can adopt an
architecture such as the one described in the next paragraph.

=nginx= in front of =gnunicorn= in front of fastapi could be put in place to
handle load balancing incoming front end requests from =BIEL=. To learn
why you might do something like that please see this [[https://stackoverflow.com/questions/20766684/what-benefit-is-added-by-using-gunicorn-nginx-flask#20766961][stackoverflow answer]]

I am not bothering myself with this at all right now, just mentioning
it. There are other architectures that could be used when we get
there.
** (Bonus/optional material) Convenience web service endpoints for BIEL UI to call (if desired)
In the interest of good user experience, it seems like it will be
important that =BIEL= only request resources that actually exist (as
defined by =translations.json=).

I've provided a few web app endpoints from which =BIEL= can
request data in order to populate its dropdown menu's in =BIEL='s
document request wizard.

You can see those by looking at ../tests/e2e/test_biel_helper.py
** Caching design
The system has two levels of caching:
1. PDF document,
   and a second lower level caching mechanism:
2. resource asset file caching

For (1), if the PDF document has previously been requested and built
and is 'fresh' according to the caching policy expressed in
file_utils.asset_file_needs_update, then immediately serve the PDF
document to the requesting user.

For (2), if any of the DocumentRequest instances's ResourceRequest
instances have been obtained from the cloud before and are 'fresh'
according to the caching policy expressed in
file_utils.asset_file_needs_update, then don't fetch said resource asset
files again, instead reuse the asset files already obtained.

Also, in level (2): translations.json is obtained
according to the caching policy expressed in
file_utils.source_file_needs_update.
** Oddities - differences from the norm in resources I've found
These are oddities that are not currently handled, either at all or
totally, either by the original system or the current system.

Examples:

| Language code | Resource type | Resource code | Oddity                                                      |
|---------------+---------------+---------------+-------------------------------------------------------------|
| ml            | tn            | any           | zip contains a manifest.yaml per usual, but the translation |
|               |               |               | notes are not in markdown they are tsv files.               |
| erk-x-erakor  | reg           | any           | manifest.json rather than manifest.txt or manifest.yaml.    |
|               |               |               | manifest.json has different structure and keys.             |
| en            | tn-wa         | any           | translations.json only lists links to PDFs                  |

** Composition of project in LOC
#+begin_src shell :results output
# pip install pygount
pygount  --folders-to-skip .DS_Store,.git,.mypy_cache,.pytest_cache,GPUCache,pdf_proof,tex,working --format=summary ../
#+end_src

#+RESULTS:
#+begin_example
    Language       Files    %     Code    %     Comment    %
-----------------  -----  ------  ----  ------  -------  ------
Python                32   23.19  3917   39.97     4328   97.59
VimL                   2    1.45  3178   32.43        2    0.05
HTML                   4    2.90  1376   14.04       58    1.31
JSON                   6    4.35   575    5.87        0    0.00
Text only              8    5.80   444    4.53        0    0.00
TOML                   2    1.45    63    0.64        7    0.16
HTML+Django/Jinja      2    1.45    61    0.62        4    0.09
YAML                   2    1.45    60    0.61        4    0.09
INI                    3    2.17    45    0.46       11    0.25
Makefile               1    0.72    30    0.31        2    0.05
Docker                 1    0.72    28    0.29       12    0.27
markdown               3    2.17    22    0.22        0    0.00
Bash                   1    0.72     1    0.01        7    0.16
__unknown__            7    5.07     0    0.00        0    0.00
__empty__              9    6.52     0    0.00        0    0.00
__binary__            55   39.86     0    0.00        0    0.00
-----------------  -----  ------  ----  ------  -------  ------
Sum total            138          9800             4435
#+end_example

** Handling links
Translation notes can have links to translation words.

Translation notes can have links to scripture verses.

Translation words can have links to translation notes.

Translation words can have links to scripture verses.

There may be other such inter-dependencies between resource types.

Problem: A document request may include translation notes, but not
translation words, or vice versa. What should be done in such cases
and others like them?

1. Remove such links including the prose leading up to them and
   following, e.g., (See also: _link_, _link_, _link_ blah blah blah)
   a. Removing just those links could render the prose that includes
   them non-sensical, for instance if later prose refers back to the
   links.
2. Instead of removing just the non-linkable links, remove the whole section
   that includes them.
   a. Loss of commentary - which is undesirable.
3. Leave the links, they'll render visually, but just won't work as
   links unless the resource type they reference is also part of the
   document request. This is the choice I have implemented.
