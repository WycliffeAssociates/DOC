#+AUTHOR:
* Design notes
** Requirements
*** Requirement
Allow creating a document out of any combination of resources from any
supported (in translations.json) language.
*** Requirement
Produce PDF final document.
*** Requirement
If generation of PDF document takes longer than X threshold of time,
then return a message to the user giving link where document will
eventually be found. E.g., display message to user in interface, say
after a cache miss on document request, or, via email. Details to be
determined.
*** Requirement
Handle TN, TA, TW, TQ, ULB, UDB resource requests. Later perhaps also
OBS, etc..
** How to run a demo for yourself
*** Get the code
Get the tools repo:

#+begin_src shell
git clone https://github.com/linearcombination/InterleavedResourcesGenerator.git
#+end_src

Then cd into the tools directory you just creating by cloning.
*** Run test suite inside the Docker container:
**** One command to take down old running containers, build the new, and run all tests
#+begin_src shell
make all
#+end_src

Warning: this will take a _long_ time!

If you don't want to have this running for so long then do this
instead:

#+begin_src shell
make unit-tests
#+end_src

The generated PDFs are copied from the Docker container to the
=docker_pdf_output= directory at the base of the repo.

For ease of stakeholders, one or more example PDFs created by the test
runs are committed to the git repo in the =docker_pdf_output=
directory.
**** Or, you can do one thing at a time using multiple Makefile targets
***** Build the container

First take down any running containers from previous runs:

#+begin_src shell
make down
#+end_src

#+begin_src shell
make build
#+end_src
***** Or, build the container the 2+Nth time from scratch

First take down any running containers from previous runs:

#+begin_src shell
make down
#+end_src

Note: Sometimes you have to be a bit more forceful with Docker and use
=docker stop idofimage= and =docker rm idofimage= to clear out the old
Docker images from a previous run.

then

#+begin_src shell
make build-no-cache
#+end_src


***** Run the tests
#+begin_src shell
make test
#+end_src
*** Run whole system inside the Docker container so that you can test in browser
#+begin_src shell
make build
make frontend-server
#+end_src
*** Run demo outside Docker container
**** Create and activate the virtual environment

#+begin_src shell
python3 -m venv .venv
source .venv/bin/activate
# or source .venv/bin/activate.fish
#+end_src

then ...

**** Install pip-tools
#+begin_src shell
make pyupgrade
#+end_src

then ...

**** Install dependencies
#+begin_src shell
make local-install-deps-dev
#+end_src

this will install production and development dependencies for our app.

Then ...

**** Install our app in editable mode

#+begin_src shell
pip install -e .
#+end_src

then ...

**** Run a quick smoke test (runs one quick test)
#+begin_src shell
make local-smoke-test-with-translation-words
#+end_src

then ...
**** Run unit tests
#+begin_src shell
make local-unit-tests
#+end_src

**** Run e2e tests
#+begin_src shell
make local-e2e-tests
#+end_src

** (Needs updating) Interactions at a high level

#+begin_src plantuml :file wa_design_sequence_diagram1.png :exports results
UI_biel -> app.document_endpoint: JSON document resources request
app.document_endopint -> DocumentGenerator: instantiate DocumentGenerator\npassing resources from request
#+end_src

#+RESULTS:
[[file:wa_design_sequence_diagram1.png]]


=DocumentGenerator= passes back a JSON dict containing any messaging and
the eventual location of the generated document for display to the
requesting user (by =BIEL=), or the document itself (depending on how
long it takes to generate).

#+begin_src plantuml :file wa_design_sequence_diagram2.png :exports results
DocumentGenerator -> DocumentGenerator: generate document request key unique to set of resources requested, e.g., a request for two resources: ml-ulb-gen-en-ulb-wa-gen.
DocumentGenerator -> ResourceFactory: using Factory Method design pattern, for each resource, instantiate Resource subclasses from document request based on resource type
DocumentGenerator <- ResourceFactory: Return either USFMResource, TAResource, TNResource, TQResource, TWResource
Resource ->  Resource: find location
Resource ->  ResourceJsonLookup: lookup: find URL for resource
Resource <-- ResourceJsonLookup: return URL
Resource ->  Resource: get (clone or download) associated files from URL
Resource <-- Resource: remember locations of acquired files
Resource -> Resource: initialize other instance vars of resource based on acquired files
Resource -> Resource: get content, i.e., convert Resource's content to HTML
DocumentGenerator -> DocumentGenerator: for each resource, concatenate each Resources' HTML
DocumentGenerator -> DocumentGenerator: enclose concatenated HTML bodies in an HTML and body element with styling
DocumentGenerator -> DocumentGenerator: convert HTML to PDF using pandoc
#+end_src

#+RESULTS:
[[file:wa_design_sequence_diagram2.png]]


A problem with the old design was that it had one class, =TnConverter=,
doing all the work. This monolithic design resulted in copious
conditional logic in order to deal with handling different types of
resources differently, e.g., USFM files, translation notes, etc..

This new version of the design has extracted logic paths unique to
each resource type and relocated them into Resource subclasses,
created via a factory method (=ResourceFactory=). These subclasses share
a clean interface: =find_location=, =get_files=, =initialize_properties=,
=get_content=. The work of =find_location= is delegated to
=ResourceJsonLookup= for all instances. =get_files= is also common to all
subclasses and not specialized from the =Resource= superclass.
Specialization in each subclass happens in the =initialize_properties=
and =get_content= methods.

This new design has also replaced the design of passing around a
dictionary within =DocumentGenerator=. Each resource that is part of a
single document request is now fully reified into its own object and
=DocumentGenerator= maintains a collection of these Resource instances.

=DocumentGenerator= also now maintains a unique key for each particular
collection of resources in the document generation request. This will
make it possible in a future design to simply lookup, if it exists, an
already finalized and generated document if one with the same
resources and order has been requested in the past. This should
greatly improve UX experience due to cutting out all the document
generation processing time.

#+begin_src plantuml :file wa_design_class_diagram_resources.png :exports results
Resource *-- ResourceJsonLookup
Resource : find_location()
Resource : get_files()
Resource : {abstract} initialize_properties()
Resource : {abstract} get_content()
note top of Resource: Partially abstract superclass that handles behavior common to all resources
Resource <|-- USFMResource
' USFMResource : +find_location()
' USFMResource : +get_files()
USFMResource : +initialize_properties()
USFMResource : +get_content()
Resource <|-- TResource
TResource : +_discover_layout()
TResource : +_convert_md2html()
note top of TResource: superclass that handles behavior common to all non-USFM resources
TResource <|-- TNResource
' TNResource : +find_location()
' TNResource : +get_files()
TNResource : +ihitialize_properties()
TNResource : +get_content()
TResource <|-- TAResource
' TAResource : +find_location()
' TAResource : +get_files()
TAResource : +ihitialize_properties()
TAResource : +get_content()
TResource <|-- TQResource
' TQResource : +find_location()
' TQResource : +get_files()
TQResource : +ihitialize_properties()
TQResource : +get_content()
TResource <|-- TWResource
' TWResource : +find_location()
' TWResource : +get_files()
TWResource : +ihitialize_properties()
TWResource : +get_content()
#+end_src

#+RESULTS:
[[file:wa_design_class_diagram_resources.png]]


The interface for ResourceLookup has not changed since the last
design, but some of the underlying implementation details have that
are not relevant to this design document.

#+begin_src plantuml :file wa_design_class_diagram.png :exports results
ResourceLookup <|-- ResourceJsonLookup
ResourceLookup : {abstract} lookup()
note top of ResourceLookup : Abstract superclass which exists only\nfor documentation and design looking\nforward to ResourceGraphQLLookup.\nIt is definitely not necessary for the system to work
ResourceJsonLookup : +lookup()
ResourceLookup <|-- ResourceGraphQLLookup
note bottom of ResourceGraphQLLookup : Does not currently exist,\n but could replace ResourceJsonLookup one day.\nWith this design, call sites could largely\nremain unchanged.
ResourceGraphQLLookup : +lookup()
#+end_src

#+RESULTS:
[[file:wa_design_class_diagram.png]]


As mentioned above a =DocumentGenerator= accepts a document generation
request composed of resources. =DocumentGenerator= instantiates the
appropriate =Resource= subclass based on the resource type. Each
=Resource= instance composes one =ResourceJsonLookup= to which it delegates
lookup tasks.

#+begin_src plantuml :file wa_design_class_diagram2.png :exports results
DocumentGenerator o-- Resource
Resource *-- ResourceJsonLookup
note top of DocumentGenerator : This used to be called TnConverter.
note bottom of Resource : Already discussed above, e.g., USFMResource, TAResource, TNResource, TQResource, or TWResource
note bottom of ResourceJsonLookup : This is where the translations.json API is queried
#+end_src

#+RESULTS:
[[file:wa_design_class_diagram2.png]]

** Caching design
The system has two levels of caching:
1. PDF document,
   and a second lower level caching mechanism:
2. resource asset file caching

For (1), if the PDF document has previously been requested and built
and is 'fresh' according to the caching policy expressed in
file_utils.asset_file_needs_update, then immediately serve the PDF
document to the requesting user.

For (2), if any of the DocumentRequest instance's ResourceRequest
instances have been obtained from the cloud before and are 'fresh'
according to the caching policy expressed in
file_utils.asset_file_needs_update, then don't fetch said resource asset
files again, instead reuse the asset files already obtained.

Also, in level (2): translations.json is obtained
according to the caching policy expressed in
file_utils.source_file_needs_update.
** Composition of project in LOC
#+begin_src shell :results output
# pip install pygount
pygount  --folders-to-skip .DS_Store,.git,.mypy_cache,.pytest_cache,GPUCache,pdf_proof,tex,working --format=summary ../
#+end_src

#+RESULTS:
#+begin_example
        Language          Files    %      Code     %     Comment    %
------------------------  -----  ------  ------  ------  -------  ------
Python                     3045   23.90  491501   45.51   180896   95.56
Text only                   218    1.71  317366   29.39        0    0.00
C                            56    0.44  149536   13.85     4189    2.21
Markdown                   2051   16.10   47222    4.37        0    0.00
YAML                          9    0.07   34256    3.17        8    0.00
JSON                         24    0.19   17441    1.62        0    0.00
ASCII armored                15    0.12    8354    0.77       90    0.05
C++                          10    0.08    5148    0.48     2255    1.19
PostScript                    1    0.01    2847    0.26      111    0.06
reStructuredText             33    0.26    1999    0.19       35    0.02
Objective-C                   2    0.02    1559    0.14     1330    0.70
HTML                         11    0.09    1048    0.10       42    0.02
S                             1    0.01     224    0.02       49    0.03
INI                           6    0.05     204    0.02       22    0.01
XSLT                          2    0.02     168    0.02        3    0.00
Makefile                      3    0.02     159    0.01       48    0.03
Graphviz                      2    0.02     141    0.01        0    0.00
PowerShell                    2    0.02     117    0.01       97    0.05
Fish                          2    0.02     108    0.01       27    0.01
HTML+Django/Jinja             2    0.02      76    0.01        8    0.00
Batchfile                     4    0.03      64    0.01        5    0.00
XML                           2    0.02      61    0.01        4    0.00
Bash                          5    0.04      59    0.01       17    0.01
Docker                        3    0.02      58    0.01       38    0.02
CSS+Lasso                     1    0.01      49    0.00       10    0.01
Tcsh                          2    0.02      45    0.00       12    0.01
TOML                         11    0.09      22    0.00        0    0.00
Cheetah                       3    0.02      22    0.00        0    0.00
JavaScript                    4    0.03      17    0.00        6    0.00
Nginx configuration file      2    0.02      12    0.00        5    0.00
Ruby                          1    0.01       6    0.00        0    0.00
Go                            1    0.01       2    0.00        0    0.00
Rust                          1    0.01       1    0.00        0    0.00
Modula-2                      1    0.01       1    0.00        0    0.00
__unknown__                3037   23.84       0    0.00        0    0.00
__generated__                24    0.19       0    0.00        0    0.00
__empty__                   415    3.26       0    0.00        0    0.00
__duplicate__                79    0.62       0    0.00        0    0.00
__binary__                 3648   28.64       0    0.00        0    0.00
------------------------  -----  ------  ------  ------  -------  ------
Sum total                 12739          1079893           189307
#+end_example

** Handling links
Translation notes can have links to translation words.

Translation notes can have links to scripture verses.

Translation words can have links to translation notes.

Translation words can have links to scripture verses.

There may be other such inter-dependencies between resource types.

Problem: A document request may include translation notes, but not
translation words, or vice versa. What should be done in such cases
and others like them?

1. Remove such links including the prose leading up to them and
   following, e.g., (See also: _link_, _link_, _link_ blah blah blah)
   a. Removing just those links could render the prose that includes
   them non-sensical, for instance if later prose refers back to the
   links.
2. Instead of removing just the non-linkable links, remove the whole section
   that includes them.
   a. Loss of commentary - which is undesirable.
3. Leave the links, they'll render visually, but just won't work as
   links unless the resource type they reference is also part of the
   document request. This is the choice I have implemented.
